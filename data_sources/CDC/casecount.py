import sysfrom csv import readerfrom pyspark import SparkContextsc = SparkContext()data = sc.textFile(sys.argv[1], 1).mapPartitions(lambda x: reader(x))output = data.map(lambda x: str(x[0]) + ',' + str(x[1]) + ',' + str(x[2]))output.saveAsTextFile("casecount.out")'''module load python/gnu/3.6.5module load spark/2.4.0rm -rf casecount.outhfs -rm -R casecount.outspark-submit --conf \spark.pyspark.python=/share/apps/python/3.6.5/bin/python \casecount.py covidCases.csvhfs -getmerge casecount.out casecount.outhfs -rm -R casecount.outhead casecount.out'''